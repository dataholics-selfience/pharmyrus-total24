"""
INPI Crawler Layer 3 - Brazilian Patent Office v28.4 DEBUG
Busca direta no INPI brasileiro para:
1. Completar abstracts faltantes (portugu√™s nativo)
2. Descobrir BRs n√£o mapeados via EPO family
3. Metadata em portugu√™s (t√≠tulo, resumo original)
"""
import asyncio
import re
import os
import logging
from typing import List, Set, Dict, Optional
from playwright.async_api import async_playwright, TimeoutError as PlaywrightTimeout
import httpx

logger = logging.getLogger("pharmyrus")


class INPICrawler:
    """Crawler para busca direta no INPI brasileiro"""
    
    def __init__(self):
        self.base_url = "https://busca.inpi.gov.br/pePI/jsp/patentes/PatenteSearchBasico.jsp"
        self.found_brs = set()
        
    async def translate_to_portuguese(self, molecule_name: str, groq_api_key: Optional[str] = None) -> str:
        """
        Traduz nome da mol√©cula para portugu√™s usando Grok X.AI (gratuito)
        Exemplos: Darolutamide ‚Üí Darolutamida, Ixazomib ‚Üí Ixazomibe
        """
        logger.info(f"üîÑ Grok translation attempt: {molecule_name}")
        
        if not groq_api_key:
            groq_api_key = os.getenv("GROQ_API_KEY")
        
        if not groq_api_key:
            logger.warning(f"‚ö†Ô∏è  GROQ_API_KEY not found in env, using original name: {molecule_name}")
            return molecule_name
        
        try:
            logger.info(f"üì° Calling Grok API for: {molecule_name}")
            
            async with httpx.AsyncClient(timeout=15.0) as client:
                response = await client.post(
                    "https://api.x.ai/v1/chat/completions",  # ‚úÖ CORRIGIDO: Grok X.AI
                    headers={
                        "Authorization": f"Bearer {groq_api_key}",
                        "Content-Type": "application/json"
                    },
                    json={
                        "model": "grok-beta",  # ‚úÖ CORRIGIDO: Grok model
                        "messages": [
                            {
                                "role": "system",
                                "content": "You are a pharmaceutical terminology expert. Translate drug molecule names from English to Brazilian Portuguese. Return ONLY the translated name, nothing else. Examples: Darolutamide‚ÜíDarolutamida, Ixazomib‚ÜíIxazomibe, Olaparib‚ÜíOlaparibe, Trastuzumab‚ÜíTrastuzumabe"
                            },
                            {
                                "role": "user",
                                "content": f"Translate to Portuguese: {molecule_name}"
                            }
                        ],
                        "temperature": 0,
                        "stream": False  # ‚úÖ BUG FIX: Era "false" (JS), agora √© False (Python)
                    }
                )
                
                logger.info(f"üìä Grok response status: {response.status_code}")
                
                if response.status_code == 200:
                    data = response.json()
                    translated = data["choices"][0]["message"]["content"].strip()
                    # Limpar poss√≠veis quotes ou markdown
                    translated = translated.replace('"', '').replace("'", "").replace('`', '').strip()
                    logger.info(f"‚úÖ Grok translated: {molecule_name} ‚Üí {translated}")
                    return translated
                else:
                    logger.error(f"‚ùå Grok API error {response.status_code}: {response.text[:200]}")
                    return molecule_name
        
        except Exception as e:
            logger.error(f"‚ùå Grok translation exception: {type(e).__name__}: {e}")
            return molecule_name
    
    async def search_inpi(
        self,
        molecule: str,
        brand: Optional[str] = None,
        dev_codes: List[str] = None,
        known_wos: List[str] = None,
        groq_api_key: Optional[str] = None
    ) -> List[Dict]:
        """
        Busca no INPI usando Playwright
        Retorna lista de BRs encontrados com metadata
        """
        logger.info(f"üáßüá∑ Layer 3 INPI: Starting search for {molecule}...")
        logger.info(f"   üìä Input: brand={brand}, dev_codes={len(dev_codes or [])}, known_wos={len(known_wos or [])}")
        
        # Traduzir para portugu√™s
        logger.info(f"üîÑ Step 1/4: Translating molecule name to Portuguese...")
        molecule_pt = await self.translate_to_portuguese(molecule, groq_api_key)
        logger.info(f"   ‚úÖ Translation result: {molecule} ‚Üí {molecule_pt}")
        
        # Construir termos de busca COMPLETOS
        logger.info(f"üîÑ Step 2/4: Building search terms...")
        search_terms = []
        
        # 1. Mol√©cula em portugu√™s (PRIORIT√ÅRIO)
        search_terms.append(molecule_pt)
        search_terms.append(molecule)  # Fallback EN
        
        # 2. Brand name em portugu√™s
        if brand:
            logger.info(f"   üîÑ Translating brand: {brand}")
            brand_pt = await self.translate_to_portuguese(brand, groq_api_key)
            logger.info(f"   ‚úÖ Brand translation: {brand} ‚Üí {brand_pt}")
            search_terms.append(brand_pt)
            search_terms.append(brand)
        
        # 3. Dev codes (n√£o precisam tradu√ß√£o)
        if dev_codes:
            logger.info(f"   üìù Adding {len(dev_codes[:5])} dev codes to search")
            search_terms.extend(dev_codes[:5])  # Top 5 dev codes
        
        # 4. WOs conhecidos para mapear BRs
        if known_wos:
            logger.info(f"   üìù Adding {len(known_wos[:10])} WOs for BR mapping")
            # Pegar top 20 WOs mais relevantes (aumentado de 10)
            for wo in known_wos[:20]:
                search_terms.append(wo)
        
        # 5. Varia√ß√µes qu√≠micas em portugu√™s
        chemical_variants_pt = [
            f"{molecule_pt} sal",
            f"{molecule_pt} composto",
            f"{molecule_pt} derivado",
            f"{molecule_pt} farmaceutico",
            f"{molecule_pt} tratamento",
            f"antagonista {molecule_pt}",
            f"inibidor {molecule_pt}"
        ]
        search_terms.extend(chemical_variants_pt)
        
        # 6. Varia√ß√µes em ingl√™s (fallback)
        chemical_variants_en = [
            f"{molecule} salt",
            f"{molecule} compound",
            f"{molecule} pharmaceutical"
        ]
        search_terms.extend(chemical_variants_en)
        
        logger.info(f"   ‚úÖ Generated {len(search_terms)} search terms")
        logger.info(f"   üìã First 10 terms: {search_terms[:10]}")
        
        all_patents = []
        screenshot_taken = False
        
        try:
            logger.info(f"üîÑ Step 3/4: Starting Playwright browser...")
            async with async_playwright() as p:
                browser = await p.chromium.launch(
                    headless=True,
                    args=[
                        '--no-sandbox',
                        '--disable-setuid-sandbox',
                        '--disable-dev-shm-usage'
                    ]
                )
                logger.info(f"   ‚úÖ Browser launched")
                
                context = await browser.new_context(
                    viewport={'width': 1920, 'height': 1080},
                    user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
                )
                logger.info(f"   ‚úÖ Context created")
                
                page = await context.new_page()
                logger.info(f"   ‚úÖ Page created")
                
                # Buscar com os primeiros 20 termos (aumentado de 15)
                total_terms = min(20, len(search_terms))
                logger.info(f"üîÑ Step 4/4: Executing {total_terms} INPI searches...")
                
                for i, term in enumerate(search_terms[:total_terms]):
                    try:
                        logger.info(f"   üîç INPI search {i+1}/{total_terms}: '{term}'")
                        
                        # Ir para p√°gina de busca
                        logger.info(f"      ‚Üí Navigating to INPI search page...")
                        await page.goto(self.base_url, wait_until='domcontentloaded', timeout=30000)
                        logger.info(f"      ‚úÖ Page loaded")
                        
                        await asyncio.sleep(2)
                        
                        # VERIFICAR SE EST√Å NA √ÅREA P√öBLICA OU LOGADA
                        page_title = await page.title()
                        page_url = page.url
                        logger.info(f"      üìÑ Page title: '{page_title}'")
                        logger.info(f"      üîó Page URL: {page_url}")
                        
                        # Verificar se h√° login required
                        login_check = await page.query_selector('input[type="password"], input[name="password"]')
                        if login_check:
                            logger.error(f"      ‚ùå LOGIN REQUIRED! Page is asking for credentials")
                            logger.error(f"      ‚ö†Ô∏è  Cannot access INPI - authentication needed")
                            
                            # Screenshot para debug
                            if not screenshot_taken:
                                screenshot_path = "/tmp/inpi_login_required.png"
                                await page.screenshot(path=screenshot_path)
                                logger.error(f"      üì∏ Screenshot saved: {screenshot_path}")
                                screenshot_taken = True
                            
                            break  # Parar buscas se login necess√°rio
                        
                        # Preencher campo de busca (ExpressaoPesquisa)
                        logger.info(f"      ‚Üí Looking for search input field...")
                        search_input = await page.query_selector('input[name="ExpressaoPesquisa"]')
                        if not search_input:
                            logger.warning(f"      ‚ö†Ô∏è  'ExpressaoPesquisa' not found, trying generic text input...")
                            search_input = await page.query_selector('input[type="text"]')
                        
                        if search_input:
                            logger.info(f"      ‚úÖ Search input found")
                            logger.info(f"      ‚Üí Filling search with: '{term}'")
                            await search_input.fill(term)
                            await asyncio.sleep(1)
                            
                            # Click buscar
                            logger.info(f"      ‚Üí Looking for submit button...")
                            submit_btn = await page.query_selector('input[type="submit"]')
                            if not submit_btn:
                                logger.warning(f"      ‚ö†Ô∏è  input[submit] not found, trying button[submit]...")
                                submit_btn = await page.query_selector('button[type="submit"]')
                            
                            if submit_btn:
                                logger.info(f"      ‚úÖ Submit button found")
                                logger.info(f"      ‚Üí Clicking submit...")
                                await submit_btn.click()
                                
                                logger.info(f"      ‚Üí Waiting for results to load...")
                                await page.wait_for_load_state('networkidle', timeout=20000)
                                await asyncio.sleep(2)
                                logger.info(f"      ‚úÖ Results page loaded")
                                
                                # Verificar se h√° resultados
                                page_content = await page.content()
                                if "Nenhum resultado encontrado" in page_content or "No results" in page_content:
                                    logger.info(f"      ‚ö†Ô∏è  No results found for '{term}'")
                                else:
                                    logger.info(f"      ‚Üí Extracting patents from results page...")
                                    
                                    # Extrair resultados
                                    patents = await self._extract_patents_from_page(page)
                                    if patents:
                                        all_patents.extend(patents)
                                        logger.info(f"      ‚úÖ Found {len(patents)} patents for '{term}'")
                                        logger.info(f"      üìã Patent numbers: {[p['patent_number'] for p in patents]}")
                                    else:
                                        logger.warning(f"      ‚ö†Ô∏è  Extraction returned 0 patents for '{term}'")
                                        
                                        # Screenshot para debug
                                        if not screenshot_taken and i < 3:  # Apenas primeiras 3 buscas
                                            screenshot_path = f"/tmp/inpi_no_results_{i+1}.png"
                                            await page.screenshot(path=screenshot_path, full_page=True)
                                            logger.info(f"      üì∏ Screenshot saved: {screenshot_path}")
                                            screenshot_taken = True
                            else:
                                logger.error(f"      ‚ùå Submit button not found!")
                        else:
                            logger.error(f"      ‚ùå Search input field not found!")
                        
                        logger.info(f"      ‚Üí Waiting 3s before next search (rate limiting)...")
                        await asyncio.sleep(3)  # Rate limiting
                    
                    except PlaywrightTimeout as e:
                        logger.error(f"      ‚è±Ô∏è  TIMEOUT searching for: {term} ({e})")
                        continue
                    except Exception as e:
                        logger.error(f"      ‚ùå ERROR searching '{term}': {type(e).__name__}: {e}")
                        continue
                
                logger.info(f"   ‚Üí Closing browser...")
                await browser.close()
                logger.info(f"   ‚úÖ Browser closed")
        
        except Exception as e:
            logger.error(f"‚ùå INPI crawler critical error: {type(e).__name__}: {e}")
            import traceback
            logger.error(f"   Traceback: {traceback.format_exc()}")
        
        # Deduplicate
        logger.info(f"üîÑ Deduplicating results...")
        unique_patents = {}
        for patent in all_patents:
            br_num = patent.get('patent_number')
            if br_num and br_num not in unique_patents:
                unique_patents[br_num] = patent
        
        result = list(unique_patents.values())
        logger.info(f"üéØ Layer 3 INPI FINAL: Found {len(result)} unique BR patents")
        
        if result:
            logger.info(f"   üìã Final BR numbers: {[p['patent_number'] for p in result]}")
        else:
            logger.warning(f"   ‚ö†Ô∏è  NO PATENTS FOUND - Check logs above for errors")
        
        return result
    
    async def _extract_patents_from_page(self, page) -> List[Dict]:
        """Extrai patentes da p√°gina de resultados INPI"""
        logger.info(f"         ‚Üí Extracting patents from HTML...")
        
        try:
            patents = await page.evaluate("""
                () => {
                    const results = [];
                    const rows = document.querySelectorAll('table tr');
                    
                    console.log('[INPI Extract] Found ' + rows.length + ' table rows');
                    
                    rows.forEach((row, idx) => {
                        const cells = row.querySelectorAll('td');
                        
                        // Skip header rows
                        if (cells.length >= 3) {
                            const firstCell = cells[0].innerText.trim();
                            
                            console.log('[INPI Extract] Row ' + idx + ': firstCell=' + firstCell);
                            
                            // Skip if header
                            if (firstCell.includes('Pedido') || firstCell.includes('N√∫mero')) {
                                console.log('[INPI Extract] Row ' + idx + ': SKIPPED (header)');
                                return;
                            }
                            
                            // Extract BR number
                            const brMatch = firstCell.match(/BR[A-Z0-9]+/);
                            if (brMatch) {
                                const patent = {
                                    patent_number: brMatch[0],
                                    title: cells[1]?.innerText?.trim() || '',
                                    filing_date: cells[2]?.innerText?.trim() || '',
                                    applicants: cells[3]?.innerText?.trim() ? [cells[3].innerText.trim()] : [],
                                    source: 'INPI'
                                };
                                
                                console.log('[INPI Extract] Row ' + idx + ': FOUND BR=' + patent.patent_number);
                                results.push(patent);
                            } else {
                                console.log('[INPI Extract] Row ' + idx + ': NO BR NUMBER FOUND');
                            }
                        }
                    });
                    
                    console.log('[INPI Extract] TOTAL EXTRACTED: ' + results.length + ' patents');
                    return results;
                }
            """)
            
            logger.info(f"         ‚úÖ Extracted {len(patents)} patents from page")
            
            if patents:
                for p in patents:
                    logger.info(f"         üìÑ {p['patent_number']}: {p.get('title', 'No title')[:60]}")
            else:
                logger.warning(f"         ‚ö†Ô∏è  Extraction returned empty list")
            
            return patents
        
        except Exception as e:
            logger.error(f"         ‚ùå Error extracting patents from page: {type(e).__name__}: {e}")
            return []
    
    async def enrich_br_from_inpi(self, br_number: str) -> Optional[Dict]:
        """
        Enriquece um BR espec√≠fico com dados do INPI
        Retorna abstract em portugu√™s, t√≠tulo original, etc
        """
        print(f"   üîç INPI enriching: {br_number}")
        
        try:
            async with async_playwright() as p:
                browser = await p.chromium.launch(headless=True, args=['--no-sandbox'])
                page = await browser.new_page()
                
                # Buscar BR espec√≠fico
                await page.goto(self.base_url, wait_until='domcontentloaded', timeout=30000)
                await asyncio.sleep(2)
                
                # Preencher com n√∫mero BR
                search_input = await page.query_selector('input[name="ExpressaoPesquisa"]')
                if search_input:
                    await search_input.fill(br_number)
                    await asyncio.sleep(1)
                    
                    submit_btn = await page.query_selector('input[type="submit"]')
                    if submit_btn:
                        await submit_btn.click()
                        await page.wait_for_load_state('networkidle', timeout=20000)
                        await asyncio.sleep(2)
                        
                        # Click no BR para ver detalhes
                        link = await page.query_selector(f'a:has-text("{br_number}")')
                        if link:
                            await link.click()
                            await page.wait_for_load_state('networkidle', timeout=20000)
                            await asyncio.sleep(2)
                            
                            # Extrair metadata da p√°gina de detalhes
                            metadata = await page.evaluate("""
                                () => {
                                    const data = {
                                        title_pt: '',
                                        abstract_pt: '',
                                        applicants: [],
                                        inventors: [],
                                        ipc_codes: []
                                    };
                                    
                                    // Procurar t√≠tulo
                                    const titleElem = document.querySelector('td:has-text("T√≠tulo"), th:has-text("T√≠tulo")');
                                    if (titleElem && titleElem.nextElementSibling) {
                                        data.title_pt = titleElem.nextElementSibling.innerText.trim();
                                    }
                                    
                                    // Procurar resumo
                                    const abstractElem = document.querySelector('td:has-text("Resumo"), th:has-text("Resumo")');
                                    if (abstractElem && abstractElem.nextElementSibling) {
                                        data.abstract_pt = abstractElem.nextElementSibling.innerText.trim();
                                    }
                                    
                                    // Procurar depositante
                                    const applicantElem = document.querySelector('td:has-text("Depositante"), th:has-text("Depositante")');
                                    if (applicantElem && applicantElem.nextElementSibling) {
                                        const apps = applicantElem.nextElementSibling.innerText.trim();
                                        data.applicants = apps.split(';').map(a => a.trim()).filter(a => a);
                                    }
                                    
                                    return data;
                                }
                            """)
                            
                            await browser.close()
                            
                            if metadata.get('title_pt') or metadata.get('abstract_pt'):
                                print(f"   ‚úÖ INPI enriched {br_number}")
                                return metadata
                
                await browser.close()
        
        except Exception as e:
            print(f"   ‚ö†Ô∏è  INPI enrichment error for {br_number}: {e}")
        
        return None


# Instance singleton
inpi_crawler = INPICrawler()
